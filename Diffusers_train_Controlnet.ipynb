{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMz6e/iSlqF4l9LJHxCRM+R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msy7822-ux/diffusers-train-controlnet/blob/main/Diffusers_train_Controlnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ControlNet学習 参考\n",
        "- https://zenn.dev/mattyamonaca/articles/23cc474bc879e6\n",
        "- https://huggingface.co/blog/train-your-controlnet"
      ],
      "metadata": {
        "id": "r4Bv958C1XNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "k7vFeUudtY2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yYAGWL1seoj"
      },
      "outputs": [],
      "source": [
        "# @title hugging face login\n",
        "\n",
        "!pip install huggingface_hub\n",
        "# !huggingface-cli login\n",
        "\n",
        "# NOTE: CLIよりこっちのが使いやすい\n",
        "import huggingface_hub\n",
        "huggingface_hub.login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install Library 1\n",
        "\n",
        "!pip install git+https://github.com/huggingface/diffusers.git transformers accelerate xformers==0.0.17 wandb\n",
        "# !wandb login"
      ],
      "metadata": {
        "id": "scQ9lfBHc7mG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title clone diffusers repo\n",
        "\n",
        "!ls\n",
        "!git clone https://github.com/huggingface/diffusers.git /content/drive/MyDrive/diffusers\n",
        "%cd /content/drive/MyDrive/diffusers"
      ],
      "metadata": {
        "id": "r3EQpmvJu-jJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title change workspace directory\n",
        "\n",
        "%cd /content/drive/MyDrive/diffusers"
      ],
      "metadata": {
        "id": "mNfDY5G1v3bK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install Library 2\n",
        "\n",
        "%cd /content/drive/MyDrive/diffusers/examples/controlnet\n",
        "\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "600drssSwaJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title HF Script\n",
        "\n",
        "from datasets import Dataset, load_dataset\n",
        "from huggingface_hub import HfApi, HfFolder\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "conditioning_paths = [\n",
        "    \"/content/drive/MyDrive/diffusers/examples/datasets/conditioning/depth1.png\"\n",
        "]\n",
        "\n",
        "def create_dataset_from_images(path):\n",
        "    \"\"\"\n",
        "    画像フォルダから画像のパスを読み込んでDatasetを作成する\n",
        "    \"\"\"\n",
        "\n",
        "    image_folder = os.path.join(path, \"image\")\n",
        "    conditioning_folder = os.path.join(path, \"conditioning\")\n",
        "\n",
        "    image = [Image.open(os.path.join(image_folder, f)) for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]\n",
        "    conditioning = [Image.open(os.path.join(conditioning_folder, f)) for f in os.listdir(conditioning_folder) if os.path.isfile(os.path.join(conditioning_folder, f))]\n",
        "    caption = [\"simple, single point perspective, one point perspective, anime,\"]*len(conditioning_paths)\n",
        "\n",
        "    dataset = Dataset.from_dict({'image': image, 'conditioning': conditioning, 'caption': caption})\n",
        "    return dataset\n",
        "\n",
        "def upload_dataset_to_hub(dataset, dataset_name, organization=None):\n",
        "    \"\"\"\n",
        "    DatasetをHugging Face Hubにアップロードする\n",
        "    \"\"\"\n",
        "    # Hugging Faceの認証トークンを取得\n",
        "    api = HfApi()\n",
        "    token = HfFolder.get_token()\n",
        "    if token is None:\n",
        "        raise ValueError(\"Hugging Faceの認証トークンが見つかりません。huggingface-cliでログインしてください。\")\n",
        "\n",
        "    # データセットをアップロード\n",
        "    if organization:\n",
        "        repo_id = f\"{organization}/{dataset_name}\"\n",
        "    else:\n",
        "        repo_id = dataset_name\n",
        "        print(repo_id, token)\n",
        "    dataset.push_to_hub(repo_id, token=token)\n",
        "\n",
        "# 画像が格納されているローカルフォルダのパス\n",
        "image_folder = '/content/drive/MyDrive/diffusers/examples/datasets'\n",
        "\n",
        "# Datasetオブジェクトを作成\n",
        "image_dataset = create_dataset_from_images(image_folder)\n",
        "\n",
        "# DatasetをHugging Face Hubにアップロード\n",
        "upload_dataset_to_hub(image_dataset, 'newDatasets', 'msy78')\n"
      ],
      "metadata": {
        "id": "y0aIvLH_zA-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Train ControlNet\n",
        "\n",
        "%cd /content/drive/MyDrive/diffusers/examples/controlnet\n",
        "\n",
        "from datasets import Dataset, load_dataset\n",
        "from huggingface_hub import HfApi, HfFolder\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "path = '/content/drive/MyDrive/diffusers/examples/datasets'\n",
        "\n",
        "conditioning_paths = [\n",
        "    \"/content/drive/MyDrive/diffusers/examples/datasets/conditioning/depth1.png\"\n",
        "]\n",
        "\n",
        "image_folder = os.path.join(path, \"image\")\n",
        "conditioning_folder = os.path.join(path, \"conditioning\")\n",
        "image = [Image.open(os.path.join(image_folder, f)) for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]\n",
        "conditioning = [Image.open(os.path.join(conditioning_folder, f)) for f in os.listdir(conditioning_folder) if os.path.isfile(os.path.join(conditioning_folder, f))]\n",
        "caption = [\"simple, single point perspective, one point perspective, anime,\"]*len(conditioning_paths)\n",
        "\n",
        "dataset = Dataset.from_dict({'image': image, 'conditioning': conditioning, 'caption': caption})\n",
        "\n",
        "# pretrained modelにsd2を使ってみる\n",
        "\n",
        "!accelerate launch train_controlnet.py \\\n",
        " --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-2-1-base\" \\\n",
        " --output_dir=\"model_out\" \\\n",
        " --dataset_name=msy78/newDatasets \\\n",
        " --conditioning_image_column=conditioning \\\n",
        " --image_column=image \\\n",
        " --caption_column=caption \\\n",
        " --resolution=512 \\\n",
        " --learning_rate=1e-5 \\\n",
        " --validation_image \"./test1.png\" \\\n",
        " --validation_prompt \"prompt1\" \\\n",
        " --train_batch_size=4 \\\n",
        " --num_train_epochs=10000 \\\n",
        " --tracker_project_name=\"controlnet\" \\\n",
        " --enable_xformers_memory_efficient_attention \\\n",
        " --checkpointing_steps=5000 \\\n",
        " --validation_steps=5000 \\\n",
        "\n"
      ],
      "metadata": {
        "id": "gqqwFgMfdLtq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}